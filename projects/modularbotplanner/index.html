<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-BBEHWW29ER"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-BBEHWW29ER');
    </script>
    
    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Hierarchical Reinforcement Learning for Swarm of Modular Bot | Somnath  Kumar</title>
    <meta name="author" content="Somnath  Kumar">
    <meta name="description" content="Enabling communication in MultiAgent Reinforcement Learning using Graph.">
    <meta name="keywords" content="somnath kumar, website, research">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img/gen_icon.png">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="http://localhost:4000/projects/modularbotplanner/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    
  </head>

  <!-- Body -->
  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Somnath </span>Kumar</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">Hierarchical Reinforcement Learning for Swarm of Modular Bot</h1>
            <p class="post-description">Enabling communication in MultiAgent Reinforcement Learning using Graph.</p>
            
            <hr>
            
              <img src="/assets/img/projects/modularbotplanner/featured.png" alt="Hierarchical Reinforcement Learning for Swarm of Modular Bot" class="post-image">
              
                  
                    <p class="post-image-caption"></p>
<center>gym-iOTA</center>
                  
              
            
          </header>

          <article>
            <p>This is my research project at <a href="https://robotics-club-iit-bhu.github.io/RoboReG/" rel="external nofollow noopener" target="_blank">RoBoReg</a>, on which I have been working for over a year till date since November 2020.</p>

<h2 id="abstract">Abstract</h2>

<p>Abstraction of policy for Multi Agent to generalize the Swarm Behaviour. Allowing easy scaling up and robustness in task. Learning heirarchially optimal policy facilitates meta learning for multi agent setup, resulting in easier learning another task for the swarm. This saves a lot of train time as the policy takes major ammount of time to learn the complex interaction of these individual agents with each other and the environment. As the distribution of the model for these interaction doesnt tend to change drastically between tasks.</p>

<h2 id="introduction">Introduction</h2>

<p>The testing has been done on a custom robot platform named iOTA. Which is a simple 4 Wheel drive on both top and bottom plates and hypotetically capable of docking(All tests are simulations with constraints added by simulator, this is done to reduce the complexity of physics).</p>

<p><img src="https://raw.githubusercontent.com/Robotics-Club-IIT-BHU/gym-iOTA/master/media/bRoll.gif" width="47%" align="left"><img src="/assets/img/projects/modularbotplanner/ModularDock.png" width="52%" align="right"></p>

<p>The whole setup is simulated in PyBullet, and we have made a simple env for our experimental testbed <a href="https://github.com/Robotics-Club-IIT-BHU/gym-iOTA" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">gym-iOTA</code></a>. There has been on a simpler 2D version of the Env for easier training and debuggin for representation learning of the environment <a href="https://github.com/hex-plex/gym-iOTA_2D" rel="external nofollow noopener" target="_blank"><code class="language-plaintext highlighter-rouge">gym-iOTA_2D</code></a>.</p>

<h2 id="pipeline">Pipeline</h2>

<p><img src="/assets/img/projects/modularbotplanner/ModularBot.png"></p>

<p>Here we have used multiple classical algorithms with learnt methods.
The main parts in the algorithm is.</p>
<ul>
  <li>Localization</li>
  <li>Clusterring</li>
  <li>High Level Planning using Policy</li>
  <li>Obstacle Avoidance</li>
  <li>Control</li>
</ul>

<h3 id="localization">Localization</h3>

<p>Localization is done using detection from multiple cameras, and averaging the position and pose as the estimates where better than just one camera. Then this pose is infused with odometry and imu using an <strong>Extended Kalman filter</strong>.</p>

<p><img src="/assets/img/projects/modularbotplanner/detection.png" alt=""></p>

<h3 id="clustering">Clustering</h3>

<p>The clustering is done using <strong>Kmeans clusters</strong>, The main use of clustering is to divide the Swarm into smaller parts for being able to learn quicker while decreasing the complexity of observation. And also making meaningful interactions as the agent is barely affected by an agent outside it’s cluster.</p>

<p><img src="/assets/img/projects/modularbotplanner/cluster.png" alt=""></p>

<h3 id="high-level-planning">High Level Planning</h3>

<p>The high level planning here refers to estimate goal position of the robot complete a certain task. The high level planning is done using Two policies, The first policy Works on individual cluster estimating parameters of an polygon, while the next estimates the distribution over the polygon and then sampling points off the distribution is taken as the target point for the robot for one action step.</p>

<p><img src="/assets/img/projects/modularbotplanner/heirPolicy.png" alt=""></p>

<p>As it can be seen one policy is under the heirarchy of the other policy and as policy $\pi_1$ is updated less frequently compared to $\pi_2$ The return will not be the same for every action taken by $\pi_1$. <strong>Hierarchical Reinforcement Learning</strong> is much suited in this <strong>Semi-Markov Decision Process</strong> over traditional Reinforcement Learning.
This also allows to learn a heirarchically optimal policy that will facilitates meta learning to different tasks.</p>

<p>The equation for update for the two policies are given by the following.</p>

\[\pi_i = \pi_i + \alpha*\delta_i\]

\[\delta_1 = V(s_{t-1}) + \gamma*R_{t} + ... + \gamma^{\tau+1}*R_{t+\tau} - V(s_{t+\tau})\]

\[\delta_2 = V(s_{t-1}) + \gamma*R_t - V(s_{t})\]

<p>Here $\tau$ is the number of time steps $\pi_2$ steps between consecutive steps of $\pi_1$</p>

<p>The final output of both combined is.
<img src="/assets/img/projects/modularbotplanner/probability_distribution.png" alt=""></p>

<p>Where the estimated polygon is seen in green, and the distribution is seen in orange. And the sampled point is seen in red.</p>

<h3 id="obstacle-avoidance">Obstacle Avoidance</h3>

<p>After the action is taken the main task is to find a path to the target position without colliding into one another. This is done using <strong>Potential Field Planning</strong>, this was the simplest algorithm for path planning that we could use in pybullet. This could easily be replaced by the nav stack in ROS.</p>

<p><img src="/assets/img/projects/modularbotplanner/potentialField.png" alt=""></p>

<h3 id="control">Control</h3>

<p>This was done using simple PD control of a 4WD, Later the docking was done using <strong>Fixed Constraints in simulator</strong> than actuallying designing and simulating a docking mechanism. While our main goal was to work on it when we would work on the hardware. The working wheels switch when the robot is flipped which is sensed using an IMU.</p>

<p><img src="/assets/img/projects/modularbotplanner/docking.png" alt=""></p>

<h2 id="limitation">Limitation</h2>

<p>After Enumerous reiteration on code, and brainstroming of ideas the project only received limited success. The project was a continual part of learning and implementation of year long journey. There are a few points of failure in the current architecture that I would like to point out.</p>

<ul>
  <li>
<strong>Insufficient Observation</strong> :- The observation for individual agent is complex for a policy \pi_2 to learn, and the representation of the cluster is done with insufficient features to policy \pi_1.</li>
  <li>
<strong>Constrained Action Space</strong> :- The current action space for both the policy are rather no encouraging to move away from the cluster or move towards a specific direction to complete the task. The architecture for the highlevel planning must be improved to allow motion in and out the cluster.</li>
  <li>
<strong>Bugs in the Environment</strong> :- The potential field algorithm is notourious for its suboptimal or worse infinite loops at corner cases for given parameters. The control is a bare minimum position control using PD and doesnt model the highly complex and dynamic System, hence the interaction of these robots in tightly packed regions are very bad as they are unable to trace the given trajectories. This is mainly true once the robots are docked.</li>
</ul>

<p>Apart from these the robot platform, as well as the codebase are robust and modular hence can be used in other applications and in future iterations of the project. This project is result of hardwork of its contributors.</p>

<h2 id="contributors">Contributors</h2>

<table>
  <tr>
  <td align="center">
     <a href="https://github.com/hex-plex" rel="external nofollow noopener" target="_blank">
    <img src="https://avatars0.githubusercontent.com/u/56990337?s=460&amp;v=4" width="100px;" alt=""><br><sub><b>Somnath Sendhil Kumar </b></sub></a><br>
    </td>
    <td align="center">
     <a href="https://github.com/surabhit-08" rel="external nofollow noopener" target="_blank">
    <img src="https://avatars3.githubusercontent.com/u/62366465?s=460&amp;v=4" width="100px;" alt=""><br><sub><b>Surabhit Gupta</b></sub></a><br>
	</td>
	<td align="center">
     <a href="https://github.com/rtharungowda" rel="external nofollow noopener" target="_blank">
    <img src="https://avatars1.githubusercontent.com/u/55887709?s=460&amp;v=4" width="100px;" alt=""><br><sub><b>R Tharun Gowda</b></sub></a><br>
	</td>
	<td align="center">
     <a href="https://github.com/Kritika-Bansal" rel="external nofollow noopener" target="_blank">
    <img src="https://avatars2.githubusercontent.com/u/57754061?s=460&amp;v=4" width="100px;" alt=""><br><sub><b>Kritika Bansal</b></sub></a><br>
	</td>
  </tr>
  <tr>
  <td><sub>Lead,Reinforcement Learning</sub></td>
  <td><sub>Hardware Design</sub></td>
  <td><sub>Clustering</sub></td>
  <td><sub>Path Planning</sub></td>
  </tr>
</table>

          </article>

        </div>

    </div>

    <!-- Footer -->    <footer class="sticky-bottom mt-5">
      <div class="container">
        © Copyright 2024 Somnath  Kumar. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script defer src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
